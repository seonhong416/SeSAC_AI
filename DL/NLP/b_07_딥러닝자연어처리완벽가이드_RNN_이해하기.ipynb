{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 1. Numpy를 사용하여 RNN 동작 구현해보기"],"metadata":{"id":"krembUqJzMKD"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"GHrLwyS5y_ub","executionInfo":{"status":"ok","timestamp":1683677714500,"user_tz":-540,"elapsed":3,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"}}},"outputs":[],"source":["import numpy as np\n","\n","timesteps = 10 # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n","input_size = 4 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n","hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량이다.\n","\n","inputs = np.random.random((timesteps, input_size)) # 입력에 해당되는 2D 텐서\n","\n","hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태는 0(벡터)로 초기화\n","# 은닉 상태의 크기 hidden_size로 은닉 상태를 만듬."]},{"cell_type":"code","source":["print(hidden_state_t) # 8의 크기를 가지는 은닉 상태. 현재는 초기 은닉 상태로 모든 차원이 0의 값을 가짐."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0uk-P75PzO0l","outputId":"83bc3245-e87e-4579-87db-0d0c69820bdd","executionInfo":{"status":"ok","timestamp":1683677733307,"user_tz":-540,"elapsed":5,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["Wx = np.random.random((hidden_size, input_size))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n","Wh = np.random.random((hidden_size, hidden_size)) # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n","b = np.random.random((hidden_size,)) # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)."],"metadata":{"id":"O_8-dkNQzUQ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 임베딩 벡터의 차원이 256이고 문장의 길이가 10으로 고정되었고, 은닉상태의 차원이 128이다. 이때 RNN의 wh,wx,b 의 크기는 얼마인가?\n","\n","- wx = 256 * 128\n","- wh = 128 * 128\n","- b = 128 "],"metadata":{"id":"FfiAw9gkC-K9"}},{"cell_type":"code","source":["print(np.shape(Wx))\n","print(np.shape(Wh))\n","print(np.shape(b))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULKZ9dnMzVkp","outputId":"e1fe28dc-b9ae-4fd5-e1aa-6577ce7b93f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8, 4)\n","(8, 8)\n","(8,)\n"]}]},{"cell_type":"code","source":["total_hidden_states = []\n","\n","# 메모리 셀 동작\n","for input_t in inputs: # 각 시점에 따라서 입력값이 입력됨.\n","  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b) # Wx * Xt + Wh * Ht-1 + b(bias)\n","  total_hidden_states.append(list(output_t)) # 각 시점의 은닉 상태의 값을 계속해서 축적\n","  print(np.shape(total_hidden_states)) # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep, output_dim)\n","  hidden_state_t = output_t\n","\n","total_hidden_states = np.stack(total_hidden_states, axis = 0)\n","# 출력 시 값을 깔끔하게 해준다.\n","\n","print(total_hidden_states) # (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서를 출력."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKm9jmdAzVrn","outputId":"82ae3b3f-10f5-4904-d8cb-7c97728e6b4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8)\n","(2, 8)\n","(3, 8)\n","(4, 8)\n","(5, 8)\n","(6, 8)\n","(7, 8)\n","(8, 8)\n","(9, 8)\n","(10, 8)\n","[[0.84715023 0.85185152 0.94789783 0.76488895 0.958207   0.84938779\n","  0.5088422  0.96349715]\n"," [0.99997134 0.99856298 0.99967925 0.99987787 0.99989994 0.99933066\n","  0.99965825 0.99999421]\n"," [0.99999082 0.99967378 0.99994559 0.99998852 0.99999002 0.99977909\n","  0.99995582 0.99999976]\n"," [0.99999391 0.99920695 0.99995371 0.99998315 0.99999162 0.99976157\n","  0.99995984 0.99999974]\n"," [0.99997461 0.99811734 0.99967025 0.99996771 0.99994798 0.99886396\n","  0.99990766 0.99999886]\n"," [0.9999905  0.99925815 0.99991277 0.9999808  0.99998462 0.99968082\n","  0.99994618 0.99999957]\n"," [0.99997944 0.99908483 0.99981222 0.99996777 0.99996263 0.99923153\n","  0.99990023 0.99999884]\n"," [0.99998835 0.99914391 0.99988498 0.99998704 0.99998384 0.999637\n","  0.99995734 0.99999973]\n"," [0.99999606 0.99967952 0.9999537  0.99998393 0.99999126 0.99991227\n","  0.9999582  0.99999967]\n"," [0.9999939  0.99964879 0.99994264 0.99999217 0.99999195 0.99987604\n","  0.99997125 0.99999986]]\n"]}]},{"cell_type":"markdown","source":["PyTorch의 nn.GRU와 nn.RNN은 출력 측면에서 shape가 항상 동일합니다. 둘 다 아래와 같은 출력값을 반환합니다.\n","\n","- output: 모든 time step에서의 hidden state 값들이 포함되어 있으며, shape는 (batch_size, seq_length, num_directions * hidden_size)입니다. 여기서 num_directions는 양방향 RNN 또는 GRU의 경우 2이고, 단방향 RNN 또는 GRU의 경우 1입니다.  \n","\n","- hidden: 마지막 time step에서의 hidden state 값들이 포함되어 있으며, shape는 (num_layers * num_directions, batch_size, hidden_size)입니다.\n","nn.RNN과 nn.GRU 모두 동일한 출력 shape를 가지지만, 내부 연산과 상태 업데이트 메커니즘은 다릅니다."],"metadata":{"id":"S9vDExPk3I4L"}},{"cell_type":"markdown","source":["# 2. PyTorch를 이용해서 RNN 구현하기"],"metadata":{"id":"dhsEIIi7zcFx"}},{"cell_type":"markdown","source":["## 2-1. nn.RNN()"],"metadata":{"id":"tZ4TEpg7zgdK"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"6DnxVxrnzXtn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_size = 5 # 입력의 크기\n","hidden_size = 8 # 은닉 상태의 크기"],"metadata":{"id":"fWnpMBtwzsdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (batch_size, time_steps, input_size)\n","inputs = torch.Tensor(1, 4, 5)\n","print('임의의 입력의 텐서 :')\n","print(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQ7QKSVhzjjY","outputId":"351b3772-586e-45a8-d1a9-b57b56ae8cc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["임의의 입력의 텐서 :\n","tensor([[[-8.9669e-20,  4.5653e-41, -5.5709e-40,  4.5653e-41, -8.9716e-20],\n","         [ 4.5653e-41, -1.0526e-38,  4.5653e-41, -8.9723e-20,  4.5653e-41],\n","         [-4.3782e+01,  4.5652e-41, -4.3782e+01,  4.5652e-41, -4.3731e+01],\n","         [ 4.5652e-41, -8.6399e-20,  4.5653e-41, -9.1319e-20,  4.5653e-41]]])\n"]}]},{"cell_type":"code","source":["cell = nn.RNN(input_size, hidden_size, batch_first=True)"],"metadata":{"id":"kzXCNEHUzkOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs, hidden = cell(inputs)"],"metadata":{"id":"eaitB1c3zoQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 time-step의 hidden_state\n","# 5개의 값이 4번 들어갔는데 출력은 8이 나옴 >> 5차원 > 8차원으로 변경됨됨 \n","print(outputs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QcboeLkYzvHw","outputId":"b1cc9882-2874-4d3a-c4bf-e895fad7eba9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 4, 8])\n"]}]},{"cell_type":"code","source":["# 첫번째 샘플의 모든 time-step의 hidden state\n","print(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEagfqNk0KVy","outputId":"ad7eaafb-c7ad-4799-f6fe-940e94eb8dcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.3999,  0.2703, -0.2019, -0.3700,  0.0727,  0.2130, -0.4390,\n","           0.0757],\n","         [-0.5890,  0.1464, -0.1237, -0.4859,  0.0540,  0.3119, -0.2035,\n","           0.1047],\n","         [ 1.0000, -0.9993,  1.0000, -0.3626, -1.0000,  0.7923,  1.0000,\n","           1.0000],\n","         [-0.2364,  0.8012, -0.0409,  0.2357,  0.4734,  0.2639, -0.8494,\n","           0.1282]]], grad_fn=<TransposeBackward1>)\n"]}]},{"cell_type":"code","source":["# 첫번째 샘플의 마지막 time-step의 hidden state\n","print(outputs[0][-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixIhCqQnzxuw","outputId":"5f01e3f4-6769-4316-9cf7-affb412cc9fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.2364,  0.8012, -0.0409,  0.2357,  0.4734,  0.2639, -0.8494,  0.1282],\n","       grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"code","source":["print(hidden.shape) # 최종 time-step의 hidden_state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0SkuoHTzwcw","outputId":"95829086-5efc-45f2-e022-2896aa335326"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 8])\n"]}]},{"cell_type":"code","source":["# 마지막 시점의 hidden state\n","hidden[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vpf6V2Boz2G3","outputId":"cc24dec5-3ce1-4b26-a04d-eaef3875b47b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.2364,  0.8012, -0.0409,  0.2357,  0.4734,  0.2639, -0.8494,  0.1282]],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["## 2-2. Deep RNN(Deep Recurrent Neural Network)"],"metadata":{"id":"i4jbiFn60U6X"}},{"cell_type":"code","source":["# (batch_size, time_steps, input_size)\n","inputs = torch.Tensor(1, 4, 5)"],"metadata":{"id":"CbrW6Idr1EOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True)\n","outputs, hidden = cell(inputs)"],"metadata":{"id":"HN71Ytqc0VaN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["첫번째 리턴값의 크기는 층이 1개였던 RNN 셀 때와 달라지지 않았습니다. 여기서는 마지막 층의 모든 시점의 은닉 상태들입니다.\n","\n"],"metadata":{"id":"713Oc0lL0tLm"}},{"cell_type":"code","source":["# 첫번째 샘플의 모든 time-step의 hidden state\n","print(outputs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_1r7_6y0gzf","outputId":"df55171f-87db-4fd3-9c89-6382f8f39a86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 4, 8])\n"]}]},{"cell_type":"markdown","source":["두번째 리턴값의 크기는 층이 1개였던 RNN 셀 때와 달라졌는데, 여기서 크기는 (층의 개수, 배치 크기, 은닉 상태의 크기)에 해당됩니다."],"metadata":{"id":"6c1Z4lrj0wN7"}},{"cell_type":"code","source":["# (층의 개수, 배치 크기, 은닉 상태의 크기)\n","print(hidden.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qg8e5vjm0XOJ","outputId":"4895a850-594f-427e-c40c-478a32732584"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1, 8])\n"]}]},{"cell_type":"markdown","source":["## 2-3. Bidirectional Recurrent Neural Network"],"metadata":{"id":"T5rvjYJx0_0_"}},{"cell_type":"markdown","source":["양방향 순환 신경망을 파이토치로 구현할 때는 nn.RNN()의 인자인 bidirectional에 값을 True로 전달하면 됩니다."],"metadata":{"id":"bEh0Fl9E1QP1"}},{"cell_type":"code","source":["# (batch_size, time_steps, input_size)\n","inputs = torch.Tensor(1, 4, 5)"],"metadata":{"id":"ruuXIPUo1AL7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cell = nn.RNN(input_size = 5, hidden_size = 8,  batch_first=True, bidirectional = True)"],"metadata":{"id":"JLlD0yzw1Gg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# outputs == 모든 시점의 은닉 상태\n","# hidden == 마지막 시점의 은닉 상태\n","outputs, hidden = cell(inputs)"],"metadata":{"id":"pm3V38j_1I0V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["첫번째 리턴값의 크기는 단뱡 RNN 셀 때보다 은닉 상태의 크기의 값이 두 배가 되었습니다. 여기서는 (배치 크기, 시퀀스 길이, 은닉 상태의 크기 x 2)의 크기를 가집니다. 이는 양방향의 은닉 상태 값들이 연결(concatenate)되었기 때문입니다."],"metadata":{"id":"xDZNhDvn1RyM"}},{"cell_type":"code","source":["# (배치 크기, 시퀀스 길이, 은닉 상태의 크기 x 2)\n","print(outputs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIFPXIcm1KGC","outputId":"41fe8fd5-8d17-4205-f01b-63e95c6c4376"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 4, 16])\n"]}]},{"cell_type":"markdown","source":["두번째 리턴값의 크기는 (2, 배치 크기, 은닉 상태의 크기)를 가집니다. 2가 의미하는 것은 하나는 순방향의 은닉 상태, 하나는 역방향의 은닉 상태이기 때문입니다."],"metadata":{"id":"P4CJDsDE1V2X"}},{"cell_type":"code","source":["# (2, 배치 크기, 은닉 상태의 크기)\n","print(hidden.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rtPQcExg1Kce","outputId":"686c35af-c98c-4774-83f7-a33f3b5e381a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1, 8])\n"]}]},{"cell_type":"code","source":["# 모든 시점의 concatenated 된 은닉 상태\n","print(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_P2zwLr1X9E","outputId":"eff9c24a-60dd-428e-f117-2b364440d056"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.2306, -0.1377,  0.4939, -0.2032, -0.2539, -0.0260, -0.2801,\n","           0.0845,  0.0308,  0.0849,  0.0666, -0.1942,  0.1453, -0.0635,\n","           0.0184,  0.1507],\n","         [ 0.2505, -0.1488,  0.3406,  0.0613, -0.2234, -0.0775, -0.4335,\n","          -0.1326,  0.0290,  0.0717,  0.0457, -0.1997,  0.1334, -0.0724,\n","           0.0239,  0.1606],\n","         [ 0.2339, -0.1191,  0.3515, -0.0511, -0.1312,  0.0762, -0.4225,\n","          -0.0964,  0.0058,  0.0999,  0.0386, -0.2158,  0.0912, -0.0954,\n","           0.0494,  0.1192],\n","         [ 0.2322, -0.1485,  0.3492, -0.0027, -0.1432, -0.0102, -0.4366,\n","          -0.0907,  0.0578,  0.0553,  0.1336, -0.1830,  0.0929, -0.1182,\n","           0.0815,  0.0595]]], grad_fn=<TransposeBackward1>)\n"]}]},{"cell_type":"code","source":["# 순방향 기준 마지막 시점의 은닉 상태\n","print(hidden[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0dvo-y4u1Y-O","outputId":"a8122f69-b194-4e0a-ab07-713e03b80706"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.2322, -0.1485,  0.3492, -0.0027, -0.1432, -0.0102, -0.4366, -0.0907]],\n","       grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"code","source":["# 역방향 기준 마지막 시점의 은닉 상태\n","print(hidden[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBuu7nIS1e8e","outputId":"092c1689-c975-4c80-def3-bf2a06baef8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0308,  0.0849,  0.0666, -0.1942,  0.1453, -0.0635,  0.0184,  0.1507]],\n","       grad_fn=<SelectBackward0>)\n"]}]}]}