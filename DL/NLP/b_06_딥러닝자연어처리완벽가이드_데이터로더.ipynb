{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["파이토치에서는 데이터를 좀 더 쉽게 다룰 수 있도록 유용한 도구로서 데이터셋(Dataset)과 데이터로더(DataLoader)를 제공합니다. 이를 사용하면 미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리까지 간단히 수행할 수 있습니다. 기본적인 사용 방법은 Dataset을 정의하고, 이를 DataLoader에 전달하는 것입니다.\n","\n","Dataset을 커스텀하여 만들 수도 있지만 여기서는 텐서를 입력받아 Dataset의 형태로 변환해주는 TensorDataset을 사용해보겠습니다.\n","\n","실습을 위해 기본적으로 필요한 파이토치의 도구들을 임포트합니다."],"metadata":{"id":"g4l-WazQYOvi"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"W_IQqNj_U_F5","executionInfo":{"status":"ok","timestamp":1683677238786,"user_tz":-540,"elapsed":4485,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset # 텐서데이터셋\n","from torch.utils.data import DataLoader # 데이터로더\n","import torch.nn.functional as F"]},{"cell_type":"markdown","source":["TensorDataset은 기본적으로 텐서를 입력으로 받습니다. 텐서 형태로 데이터를 정의합니다.\n","\n"],"metadata":{"id":"_KkxMQ-5YSOk"}},{"cell_type":"code","source":["x_train  =  torch.FloatTensor([[73,  80,  75], \n","                               [93,  88,  93], \n","                               [89,  91,  90], \n","                               [96,  98,  100],   \n","                               [73,  66,  70]])  \n","y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"],"metadata":{"id":"SPjW-gNwVFMF","executionInfo":{"status":"ok","timestamp":1683677247009,"user_tz":-540,"elapsed":348,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["이제 이를 TensorDataset의 입력으로 사용하고 dataset으로 저장합니다."],"metadata":{"id":"djejd_3aYUYx"}},{"cell_type":"code","source":["dataset = TensorDataset(x_train, y_train)"],"metadata":{"id":"py7rueW1VGfB","executionInfo":{"status":"ok","timestamp":1683677258450,"user_tz":-540,"elapsed":354,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["파이토치의 데이터셋을 만들었다면 데이터로더를 사용 가능합니다. 데이터로더는 기본적으로 2개의 인자를 입력받는다. 하나는 데이터셋, 미니 배치의 크기입니다. 이때 미니 배치의 크기는 통상적으로 2의 배수를 사용합니다. (ex) 64, 128, 256...) 그리고 추가적으로 많이 사용되는 인자로 shuffle이 있습니다. shuffle=True를 선택하면 Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꿉니다.\n","\n","사람도 같은 문제지를 계속 풀면 어느 순간 문제의 순서에 익숙해질 수 있습니다. 예를 들어 어떤 문제지의 12번 문제를 풀면서, '13번 문제가 뭔지는 기억은 안 나지만 어제 풀었던 기억으로 정답은 5번이었던 것 같은데' 하면서 문제 자체보단 순서에 익숙해질 수 있다는 것입니다. 그럴 때 문제지를 풀 때마다 문제 순서를 랜덤으로 바꾸면 도움이 될 겁니다. 마찬가지로 모델이 데이터셋의 순서에 익숙해지는 것을 방지하여 학습할 때는 이 옵션을 True를 주는 것을 권장합니다."],"metadata":{"id":"KllMRJq8YZqy"}},{"cell_type":"code","source":["dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"],"metadata":{"id":"xFm7NnmgVH1s","executionInfo":{"status":"ok","timestamp":1683677332402,"user_tz":-540,"elapsed":3,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["이제 모델과 옵티마이저를 설계합니다. nn.Linear(input_dim, output_dim)이므로 입력층에 뉴런이 3개, 출력층에 뉴런이 1개인 구조입니다. 그리고 하나의 뉴런에는 하나의 숫자가 맵핑되므로 선형 회귀 식으로 나열한다면 다음과 같은 식이 나올겁니다.  \n","\n","$H(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b$"],"metadata":{"id":"5YF4B-kLYcDM"}},{"cell_type":"code","source":["model = nn.Linear(3, 1)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "],"metadata":{"id":"26bhT-JaVNGL","executionInfo":{"status":"ok","timestamp":1683677352260,"user_tz":-540,"elapsed":438,"user":{"displayName":"주식회사한시경","userId":"01036671795204052858"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["학습을 할 때는 각 에포크마다 데이터로더로부터 배치 크기만큼(이 예제에서는 2)의 데이터를 꺼내서 학습을 진행합니다. 배치 데이터에 대한 이해를 위해서 배치 크기만큼의 데이터를 꺼내서 사용할 때마다 크기를 출력해보았습니다. 그리고 각 배치 데이터마다의 손실을 계속 출력하고, 에포크가 끝났을 때는 해당 배치 데이터마다의 손실을 평균내어서 해당 에포크의 손실로 판단합니다."],"metadata":{"id":"vIESnetrYdVh"}},{"cell_type":"code","source":["nb_epochs = 2\n","for epoch in range(1, nb_epochs + 1):\n","  train_loss = 0\n","  print('-' * 5, epoch, 'Epoch 진행', '-' * 45)\n","  for batch_idx, samples in enumerate(dataloader):\n","    x_train, y_train = samples\n","    print(batch_idx + 1,'배치 데이터의 크기 :', x_train.shape)\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 계산\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","    train_loss += cost.item()\n","\n","    print('해당 배치의 Loss: {:.6f}'.format(cost.item()))\n","\n","  train_loss /= len(dataloader)\n","  print()\n","  print(f'==> Epoch Loss: {train_loss:.4f}')\n","\n","  # 해당 배치 기준으로 loss 를 구함 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jK7VEQiaVQxJ","outputId":"c5db03f0-3c85-42e1-d3fb-16a038646460"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----- 1 Epoch 진행 ---------------------------------------------\n","1 배치 데이터의 크기 : torch.Size([2, 3])\n","해당 배치의 Loss: 51028.203125\n","2 배치 데이터의 크기 : torch.Size([2, 3])\n","해당 배치의 Loss: 22942.742188\n","3 배치 데이터의 크기 : torch.Size([1, 3])\n","해당 배치의 Loss: 2832.570801\n","\n","==> Epoch Loss: 25601.1720\n","----- 2 Epoch 진행 ---------------------------------------------\n","1 배치 데이터의 크기 : torch.Size([2, 3])\n","해당 배치의 Loss: 2230.581055\n","2 배치 데이터의 크기 : torch.Size([2, 3])\n","해당 배치의 Loss: 471.627136\n","3 배치 데이터의 크기 : torch.Size([1, 3])\n","해당 배치의 Loss: 90.389214\n","\n","==> Epoch Loss: 930.8658\n"]}]}]}