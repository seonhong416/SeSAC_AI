{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"googLeNet_SEmodule_applied.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"5ZiAVJEcNVe1","executionInfo":{"status":"ok","timestamp":1626746645548,"user_tz":-540,"elapsed":2003,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Dense, Activation, add, Flatten, GlobalAveragePooling2D, concatenate, Reshape, multiply\n","from keras.models import Model\n","\n","from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Dense, Activation, add, Flatten, AveragePooling2D, concatenate\n","from keras.models import Model\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import tensorflow as tf\n","from keras.utils import np_utils\n","\n","width = 32\n","height = 32\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F1PIxfu-FJTd"},"source":["https://keras.io/api/layers/"]},{"cell_type":"code","metadata":{"id":"8w4-9oE4Ngaj","executionInfo":{"status":"ok","timestamp":1626746608724,"user_tz":-540,"elapsed":402,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["num_classes = 10\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-GhJpHuW02A","executionInfo":{"status":"ok","timestamp":1626746608725,"user_tz":-540,"elapsed":14,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["validation_images, validation_labels = x_train[:500], y_train[:500]\n","train_images, train_labels = x_train[500:], y_train[500:]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qCGvbXliD5Au","executionInfo":{"status":"ok","timestamp":1626746608725,"user_tz":-540,"elapsed":13,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}},"outputId":"31832ac6-4b28-4219-d5f6-eb316d3c22dd"},"source":["train_images.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(49500, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"jtiNRXEGy135","executionInfo":{"status":"ok","timestamp":1626746608726,"user_tz":-540,"elapsed":12,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["def SEmodule(pre_layer, ch, r): \n","  #pre_layer : 입력(w,h,c), ch : channel, r :16\n","  \n","    x = GlobalAveragePooling2D()(pre_layer)\n","\n","    x = Dense(int(ch/r), activation='relu')(x) #int(ch/r) 나누어 떨어지지 않을 수 있기 때문 >> 정수\n","    \n","    x = Dense(ch, activation='sigmoid')(x)\n","\n","    x = Reshape((1, 1, ch))(x) #1x1xchannel vector로 변환 \n","\n","    x = multiply([pre_layer,x]) # 가중치 반영부분 (channel by channel별로 가중치)\n","    \n","    return x"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWFlCh3bHU2p","executionInfo":{"status":"ok","timestamp":1626746608726,"user_tz":-540,"elapsed":11,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["def inception(x, filters): \n","    pre_layer = x\n","    \n","    f1,f2,f3,f4 = filters\n","\n","    # 1x1\n","    conv1 = Conv2D(f1, kernel_size=(1,1), padding='same', activation='relu')(pre_layer)\n","    \n","    # 1x1 & 3x3\n","    conv2 = Conv2D(f4  , kernel_size=(1,1), padding='same', activation='relu')(pre_layer)\n","    conv2 = Conv2D(f2, kernel_size=(3,3), padding='same', activation='relu')(conv2)\n","\n","    # 1x1 & 5x5\n","    conv3 = Conv2D(f4, kernel_size=(1,1), padding='same', activation='relu')(pre_layer)\n","    conv3 = Conv2D(f3, kernel_size=(5,5), padding='same', activation='relu')(conv3)\n","    \n","    # pooling & 1x1\n","    max_pool = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(pre_layer)\n","    max_pool = Conv2D(f4, kernel_size=(1,1), padding='same')(max_pool)\n","\n","    # output = [None(batch_size), w,h,c], c 기준 concatenate (axis = -1 )\n","    concat = concatenate([conv1, conv2, conv3, max_pool], axis=-1)\n","    \n","    x = SEmodule(concat, f1+f2+f3+f4, 16)\n","\n","    return x #concat\n","    "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"_BQRbgfkHbCV","executionInfo":{"status":"ok","timestamp":1626746647517,"user_tz":-540,"elapsed":869,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["input_shape = x_train[0].shape    \n","inputs = Input(shape=input_shape)\n","\n","# conv랑 batch 사이에 max pooling 들어가야 하나, cifar 데이터에선 크기 너무 줄어들어서 뺐음\n","x = Conv2D(64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(inputs)\n","x = BatchNormalization()(x)\n","x = Conv2D(192, kernel_size=(3,3), padding='same', activation='relu')(x)\n","x = BatchNormalization()(x) \n","\n","\n","# inception 3a\n","x = inception(x,[64,128,32,32])\n","# inception 3b\n","x = inception(x,[128,192,96,64])\n","x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n","\n","# inception 4a\n","x = inception(x,[192,208,48,64])\n","aux1 = AveragePooling2D(pool_size=(5,5),strides = 3, padding='valid')(x)\n","aux1 = Conv2D(128, kernel_size=(1,1), padding='same', activation='relu')(aux1)\n","aux1 = Flatten()(aux1)\n","aux1 = Dense(512, activation='relu')(aux1)\n","aux1 = Dense(10, activation='softmax')(aux1)\n","\n","# inception 4b\n","x = inception(x,[160,224,64,64])\n","\n","\n","# inception 4c\n","x = inception(x,[128,256,64,64])\n","# inception 4d\n","x = inception(x,[112,288,64,64])\n","aux2 = AveragePooling2D(pool_size=(5,5),strides = 3, padding='valid')(x)\n","aux2 = Conv2D(128, kernel_size=(1,1), padding='same', activation='relu')(aux2)\n","aux2 = Flatten()(aux2)\n","aux2 = Dense(832, activation='relu')(aux2)\n","aux2 = Dense(10, activation='softmax')(aux2)\n","\n","\n","# inception 4e\n","x = inception(x,[256,320,128,128])\n","\n","\n","# inception 5a\n","x = inception(x,[256,320,128,128])\n","# inception 5b\n","x = inception(x,[384,384,128,128])\n","x = GlobalAveragePooling2D()(x)\n","x = Dropout(0.4)(x)\n","x = Flatten()(x)\n","outputs = Dense(10, activation='softmax')(x)\n","\n","model = Model(inputs=inputs, outputs=[aux1, aux2, outputs])\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', loss_weights=[0.3,0.3,1.0], metrics=['accuracy']) \n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLio7DUSOqPi","executionInfo":{"status":"aborted","timestamp":1626746608973,"user_tz":-540,"elapsed":255,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKIGz5YMWrKr","executionInfo":{"status":"aborted","timestamp":1626746608974,"user_tz":-540,"elapsed":256,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","validation_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o73IuB0RXFoe","executionInfo":{"status":"aborted","timestamp":1626746608974,"user_tz":-540,"elapsed":256,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["history = model.fit_generator(train_datagen.flow(train_images,train_labels, batch_size = 32), \n","                    validation_data = validation_datagen.flow(validation_images, validation_labels, batch_size = 32),\n","                    epochs = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nouTQsGTOR9i","executionInfo":{"status":"aborted","timestamp":1626746608975,"user_tz":-540,"elapsed":256,"user":{"displayName":"양진욱","photoUrl":"","userId":"14741531518039695168"}}},"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['dense_13_accuracy']\n","val_acc = history.history['val_dense_13_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(10)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]}]}