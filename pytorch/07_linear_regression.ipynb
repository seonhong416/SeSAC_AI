{"cells":[{"cell_type":"markdown","metadata":{"id":"bL46QBSEifE7"},"source":["## nn.Module로 구현하는 선형 회귀"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"A4-EgGpoIwkv"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TQhYbdN1ho-Q"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x237c9966170>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(1)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"U1h6vmHchqzR"},"outputs":[],"source":["# 데이터\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[2], [4], [6]])"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"lriiiCgVhtrg"},"outputs":[],"source":["# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n","model = nn.Linear(1,1)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"T-gjgSvUhvOR"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Parameter containing:\n","tensor([[0.5153]], requires_grad=True), Parameter containing:\n","tensor([-0.4414], requires_grad=True)]\n"]}],"source":["print(list(model.parameters()))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"gDZKl8Lih54x"},"outputs":[],"source":["#학습률(learning rate)은 0.01로 정합니다.\n","\n","# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n","optimizer = optim.SGD(model.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"K7j32RzYh77B"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch    0/2000 Cost: 13.103541\n","Epoch  100/2000 Cost: 0.002791\n","Epoch  200/2000 Cost: 0.001724\n","Epoch  300/2000 Cost: 0.001066\n","Epoch  400/2000 Cost: 0.000658\n","Epoch  500/2000 Cost: 0.000407\n","Epoch  600/2000 Cost: 0.000251\n","Epoch  700/2000 Cost: 0.000155\n","Epoch  800/2000 Cost: 0.000096\n","Epoch  900/2000 Cost: 0.000059\n","Epoch 1000/2000 Cost: 0.000037\n","Epoch 1100/2000 Cost: 0.000023\n","Epoch 1200/2000 Cost: 0.000014\n","Epoch 1300/2000 Cost: 0.000009\n","Epoch 1400/2000 Cost: 0.000005\n","Epoch 1500/2000 Cost: 0.000003\n","Epoch 1600/2000 Cost: 0.000002\n","Epoch 1700/2000 Cost: 0.000001\n","Epoch 1800/2000 Cost: 0.000001\n","Epoch 1900/2000 Cost: 0.000000\n","Epoch 2000/2000 Cost: 0.000000\n"]}],"source":["# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n","nb_epochs = 2000\n","for epoch in range(nb_epochs+1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n","\n","    # cost로 H(x) 개선하는 부분\n","    # gradient를 0으로 초기화\n","    optimizer.zero_grad()\n","    # 비용 함수를 미분하여 gradient 계산\n","    cost.backward() # backward 연산\n","    # W와 b를 업데이트\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","    # 100번마다 로그 출력\n","      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","      ))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Lnm4Ev4Wh_3x"},"outputs":[{"name":"stdout","output_type":"stream","text":["훈련 후 입력이 4일 때의 예측값 : tensor([[7.9989]], grad_fn=<AddmmBackward0>)\n"]}],"source":["# 임의의 입력 4를 선언\n","new_var =  torch.FloatTensor([[4]]) \n","# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n","pred_y = model(new_var) # forward 연산\n","# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n","print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) "]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Om0xHzSSiHRB"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Parameter containing:\n","tensor([[1.9994]], requires_grad=True), Parameter containing:\n","tensor([0.0014], requires_grad=True)]\n"]}],"source":["print(list(model.parameters()))"]},{"cell_type":"markdown","metadata":{"id":"THwLLpl-inGA"},"source":["## nn.Module로 구현하는 다중 선형 회귀 구현하기"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"dNMZgnpBioqY"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"tBIJke1OirGA"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x237c9966170>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(1)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"9_fpS8Pyisbw"},"outputs":[],"source":["# 데이터\n","x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"mIeLX3IVit4Z"},"outputs":[],"source":["# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n","model = nn.Linear(3,1)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"8tYXvF70ixFh"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Parameter containing:\n","tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n","tensor([0.2710], requires_grad=True)]\n"]}],"source":["print(list(model.parameters()))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"rs9KwwwoizSw"},"outputs":[],"source":["optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "]},{"cell_type":"code","execution_count":23,"metadata":{"id":"U4lHRxgSi1PT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch    0/2000 Cost: 31667.599609\n","Epoch  100/2000 Cost: 0.225993\n","Epoch  200/2000 Cost: 0.223911\n","Epoch  300/2000 Cost: 0.221941\n","Epoch  400/2000 Cost: 0.220059\n","Epoch  500/2000 Cost: 0.218271\n","Epoch  600/2000 Cost: 0.216575\n","Epoch  700/2000 Cost: 0.214950\n","Epoch  800/2000 Cost: 0.213413\n","Epoch  900/2000 Cost: 0.211952\n","Epoch 1000/2000 Cost: 0.210559\n","Epoch 1100/2000 Cost: 0.209230\n","Epoch 1200/2000 Cost: 0.207967\n","Epoch 1300/2000 Cost: 0.206762\n","Epoch 1400/2000 Cost: 0.205618\n","Epoch 1500/2000 Cost: 0.204529\n","Epoch 1600/2000 Cost: 0.203481\n","Epoch 1700/2000 Cost: 0.202486\n","Epoch 1800/2000 Cost: 0.201539\n","Epoch 1900/2000 Cost: 0.200634\n","Epoch 2000/2000 Cost: 0.199770\n"]}],"source":["nb_epochs = 2000\n","for epoch in range(nb_epochs+1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","    # model(x_train)은 model.forward(x_train)와 동일함.\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n","\n","    # cost로 H(x) 개선하는 부분\n","    # gradient를 0으로 초기화\n","    optimizer.zero_grad()\n","    # 비용 함수를 미분하여 gradient 계산\n","    cost.backward()\n","    # W와 b를 업데이트\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","    # 100번마다 로그 출력\n","      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","      ))"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"9XalXsW0i3GH"},"outputs":[{"name":"stdout","output_type":"stream","text":["훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.2306]], grad_fn=<AddmmBackward0>)\n"]}],"source":["# 임의의 입력 [73, 80, 75]를 선언\n","new_var =  torch.FloatTensor([[73,80,75]]) \n","# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n","pred_y = model(new_var) \n","print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "]},{"cell_type":"code","execution_count":25,"metadata":{"id":"OvYfBm-Ui4ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Parameter containing:\n","tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n","tensor([0.2802], requires_grad=True)]\n"]}],"source":["print(list(model.parameters()))"]},{"cell_type":"markdown","metadata":{"id":"fhSotUoajf75"},"source":["## 클래스로 파이토치 모델 구현하기"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"mmqynwAEjg7Q"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"7_jxlh3EjkBp"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x237c9966170>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(1)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"9qjiSPpqjmDx"},"outputs":[],"source":["# 데이터\n","x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"]},{"cell_type":"code","execution_count":169,"metadata":{"id":"UcMtpJa1jpbB"},"outputs":[],"source":["class MultivariateLinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(3,1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n","\n","    def forward(self, x):\n","        return self.linear(x)"]},{"cell_type":"code","execution_count":173,"metadata":{"id":"GGv9P6Mejr_R"},"outputs":[],"source":["model = MultivariateLinearRegressionModel()"]},{"cell_type":"code","execution_count":174,"metadata":{"id":"4_YWqHrPjviJ"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=0.5)"]},{"cell_type":"code","execution_count":175,"metadata":{"id":"vyqk51tWjxUK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch    0/2000 Cost: 45074.824219\n","Epoch  100/2000 Cost: 0.794435\n","Epoch  200/2000 Cost: 0.685407\n","Epoch  300/2000 Cost: 0.616763\n","Epoch  400/2000 Cost: 0.546730\n","Epoch  500/2000 Cost: 0.478668\n","Epoch  600/2000 Cost: 0.414684\n","Epoch  700/2000 Cost: 0.356314\n","Epoch  800/2000 Cost: 0.304570\n","Epoch  900/2000 Cost: 0.259995\n","Epoch 1000/2000 Cost: 0.222672\n","Epoch 1100/2000 Cost: 0.192256\n","Epoch 1200/2000 Cost: 0.168139\n","Epoch 1300/2000 Cost: 0.149536\n","Epoch 1400/2000 Cost: 0.135564\n","Epoch 1500/2000 Cost: 0.125356\n","Epoch 1600/2000 Cost: 0.118110\n","Epoch 1700/2000 Cost: 0.113114\n","Epoch 1800/2000 Cost: 0.109768\n","Epoch 1900/2000 Cost: 0.107592\n","Epoch 2000/2000 Cost: 0.106228\n"]}],"source":["nb_epochs = 2000\n","for epoch in range(nb_epochs+1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","    # model(x_train)은 model.forward(x_train)와 동일함.\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n","\n","    # cost로 H(x) 개선하는 부분\n","    # gradient를 0으로 초기화\n","    optimizer.zero_grad()\n","    # 비용 함수를 미분하여 gradient 계산\n","    cost.backward()\n","    # W와 b를 업데이트\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","    # 100번마다 로그 출력\n","      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","      ))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMJlfY1sF2xq7fk61SUPNMe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
