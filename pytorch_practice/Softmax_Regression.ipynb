{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-3 소프트맥스 회귀의 비용 함수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1847749b110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치로 소프트맥스의 비용 함수 구현하기(로우-레벨)\n",
    "\n",
    "z = torch.FloatTensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "hypothesis = F.softmax(z, dim=0)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
      "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
      "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = F.softmax(z, dim=1)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randint(5, (3,)).long()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 원소가 0의 값을 가진 3 × 5 텐서 생성\n",
    "y_one_hot = torch.zeros_like(hypothesis)  # 모든 원소가 0인 3x5 텐서 만들기\n",
    "y_one_hot.scatter_(1, y.unsqueeze(1), 1) # 연산 뒤에 _ 는 덮어쓰기 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [2],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "print(y.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4689, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
       "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
       "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치로 스프트맥스의 비용 함수 구현하기 (하이-레벨)\n",
    "\n",
    "# Low level\n",
    "torch.log(F.softmax(z, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
       "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
       "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High level\n",
    "F.log_softmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4689, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low level\n",
    "# 첫번째 수식\n",
    "(y_one_hot * -torch.log(F.softmax(z, dim=1))).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4689, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두번째 수식\n",
    "(y_one_hot * - F.log_softmax(z, dim=1)).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4689, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High level\n",
    "# 세번째 수식\n",
    "F.nll_loss(F.log_softmax(z, dim=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4689, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네번째 수식\n",
    "F.cross_entropy(z, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-4 소프트맥스 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1847749b110>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# 소프트맥스 회귀 구현하기(로우-레벨)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "y_one_hot = torch.zeros(8, 3)\n",
    "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
    "print(y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros((1, 3), requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.704200\n",
      "Epoch  200/1000 Cost: 0.623000\n",
      "Epoch  300/1000 Cost: 0.565717\n",
      "Epoch  400/1000 Cost: 0.515291\n",
      "Epoch  500/1000 Cost: 0.467662\n",
      "Epoch  600/1000 Cost: 0.421278\n",
      "Epoch  700/1000 Cost: 0.375401\n",
      "Epoch  800/1000 Cost: 0.329766\n",
      "Epoch  900/1000 Cost: 0.285072\n",
      "Epoch 1000/1000 Cost: 0.248155\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # 가설\n",
    "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) \n",
    "\n",
    "    # 비용 함수\n",
    "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.704200\n",
      "Epoch  200/1000 Cost: 0.623000\n",
      "Epoch  300/1000 Cost: 0.565717\n",
      "Epoch  400/1000 Cost: 0.515291\n",
      "Epoch  500/1000 Cost: 0.467662\n",
      "Epoch  600/1000 Cost: 0.421278\n",
      "Epoch  700/1000 Cost: 0.375402\n",
      "Epoch  800/1000 Cost: 0.329766\n",
      "Epoch  900/1000 Cost: 0.285072\n",
      "Epoch 1000/1000 Cost: 0.248155\n"
     ]
    }
   ],
   "source": [
    "# 소프트맥스 회귀 구현하기(하이-레벨)\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros((1, 3), requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산\n",
    "    z = x_train.matmul(W) + b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 회귀 nn.Module로 구현하기\n",
    "\n",
    "# 모델을 선언 및 초기화. 4개의 특성을 가지고 3개의 클래스로 분류. input_dim=4, output_dim=3.\n",
    "model = nn.Linear(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.616785\n",
      "Epoch  100/1000 Cost: 0.658891\n",
      "Epoch  200/1000 Cost: 0.573444\n",
      "Epoch  300/1000 Cost: 0.518151\n",
      "Epoch  400/1000 Cost: 0.473266\n",
      "Epoch  500/1000 Cost: 0.433516\n",
      "Epoch  600/1000 Cost: 0.396563\n",
      "Epoch  700/1000 Cost: 0.360914\n",
      "Epoch  800/1000 Cost: 0.325392\n",
      "Epoch  900/1000 Cost: 0.289178\n",
      "Epoch 1000/1000 Cost: 0.254148\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 회귀 클래스로 구현하기\n",
    "\n",
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 3) # Output이 3!\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 2.637636\n",
      "Epoch  100/1000 Cost: 0.647903\n",
      "Epoch  200/1000 Cost: 0.564643\n",
      "Epoch  300/1000 Cost: 0.511043\n",
      "Epoch  400/1000 Cost: 0.467249\n",
      "Epoch  500/1000 Cost: 0.428281\n",
      "Epoch  600/1000 Cost: 0.391924\n",
      "Epoch  700/1000 Cost: 0.356742\n",
      "Epoch  800/1000 Cost: 0.321577\n",
      "Epoch  900/1000 Cost: 0.285617\n",
      "Epoch 1000/1000 Cost: 0.250818\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  5-5 소프트맥스 회귀로 MIST 데이터 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토치비전 이란?\n",
    "# torchvision은 유명한 데이터셋들, 이미 구현되어져있는 유명한 모델들, 일반적인 이미지 전처리 도구들을 포함하고있는 패키지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 28551962.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 35142353.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 7514692.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, # 배치 크기는 100\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535150647\n",
      "Epoch: 0002 cost = 0.359577745\n",
      "Epoch: 0003 cost = 0.331264287\n",
      "Epoch: 0004 cost = 0.316404700\n",
      "Epoch: 0005 cost = 0.307107002\n",
      "Epoch: 0006 cost = 0.300456554\n",
      "Epoch: 0007 cost = 0.294933408\n",
      "Epoch: 0008 cost = 0.290956199\n",
      "Epoch: 0009 cost = 0.287074119\n",
      "Epoch: 0010 cost = 0.284515589\n",
      "Epoch: 0011 cost = 0.281914055\n",
      "Epoch: 0012 cost = 0.279526860\n",
      "Epoch: 0013 cost = 0.277636588\n",
      "Epoch: 0014 cost = 0.275874794\n",
      "Epoch: 0015 cost = 0.274422735\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8883000016212463\n",
      "Label:  7\n",
      "Prediction:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
